## Zookeeper工作机制

zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接收观察者的注册，一旦这些数据的状态发生变化，zookeeper就将负责通知在zookeeper上注册的那些观察者做出相应的回应。

### zookeeper的特点

1.一个领导者（leader），多个随从（follower）组成的集群

2.集群中只要有半数以上的节点存活，zookeeper集群就能正常服务，所以zookeeper适合安装奇数台服务器

3.全局数据一致性：每个server保存一份相同的数据副本，client无论连接到哪一台server，数据都是一致的

4.更新请求顺序执行，来自同一个client的更新请求将按照其发送的顺序依次执行

5.数据更新原子性，一次数据更新要么成功，要么失败

6.实时性，在一定时间范围内，client都能读取到最新的数据

### 数据结构

zookeeper的数据结构与linux文件系统类似，整体上可以看做是一棵树，每个节点称作一个znode，每一个znode默认能够存储1MB的数据，每个znode都可以通过其路径唯一标识

### zookeeper的应用场景

统一命名服务，统一配置管理，统一集群管理，服务器节点动态上下线，软负载均衡

### zookeeper配置参数（zoo.cfg）

1.tickTime = 2000：通信心跳时间，zookeeper服务器与客户端心跳时间，单位毫秒

2.initTime = 10：LF初始通信时限（leader-follower）

leader和follower初始连接时能容忍的最多心跳数（tickTime的数量）

3.syncLimit = 5，LF同步通信时限

leader和follower之间通信时间如果超过syncLimit * tickTime，leader认为Follower死亡

4.dataDir：保存zookeeper中的数据

默认是tmp目录，这个目录下存放的都是Linux中的临时文件，会定期删除，所以不能使用这个目录

5.clientPort = 2181：客户端连接端口

### zookeeper选举机制

一.集群第一次启动：（集群中有5台服务器）

1.服务器1启动，发起一次选举，服务器1投给自己一票，此时服务器1为一票，不够半数以上，选举无法完成，服务器1状态保持为looking

2.服务器2启动，再发起一次选举，服务器1和2分别投自己一票并交换选票信息，此时服务器1发现服务器2的myid比自己目前投票推举的（服务器1）大，更改选票为推举服务器2。此时服务器1票数为0，服务器2票数为2票，没有超过半数，选举无法完成，服务器1和服务器2状态保持为looking

3.服务器3启动，发起一次选举，此时服务器1和2都会改选为服务器3，此时1是0票，2是0票，3是3票，超过半数，3成为leader，1和2成为follower

4.服务器4启动，发起一次选举，此时1，2，3已经不是looking状态，不会更改选票信息，并且已经有了leader，服务器4即使myid比服务器3大，依然只会给自己投一票，前面的服务器不会再给4投票，所以4会成为follower

5.5同4一样

二.集群非第一次启动

当zookeeper集群中的一台服务器出现以下两种情况之一时，就会开始进行leader选举：

1.服务器初始化启动

2.服务器运行期间无法和leader保持连接

当一台服务器进入leader选举流程时，当前集群也可能处于以下两种状态：

1.集群中本来就存在leader，（leader假死）

对于第一种已经存在leader的情况，机器试图去选举leader时，会被告知当前服务器的leader信息，对于该机器来说，仅仅需要和leader机器建立连接，并进行状态同步即可

2.集群中确实不存在leader

假设zookeeper集群由五台服务器组成，sid分别为1,2,3,4,5，zxid为8,8,8,7,7，并且sid为3的是leader，某一时刻，3和5出现故障，因此开始进行leader选举

sid为1,2,4的机器投票情况，（epoch，zxid，sid）

~~~wiki
sid：服务器id，用来唯一标识一台zookeeper集群中的机器，每台机器不能重复，和myid一致
zxid：事务id，zxid是一个事务id，用来标识一次服务器状态的变更，在某一时刻，集群中的每台机器的zxid并不一定完全相等，这和zookeeper服务器对于客户端更新请求的处理逻辑有关
epoch：每个leader任期的代号，没有leader时同一轮投票过程的逻辑时钟值是相同的，每投完一次票这个数据就会增加
~~~



